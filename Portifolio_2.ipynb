{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ad07d2",
   "metadata": {},
   "source": [
    "## Agentes inteligentes, ambientes e racionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91464cb5",
   "metadata": {},
   "source": [
    "Agentes inteligentes são agentes capazes de realizar as ações mais \"corretas\" de acordo com seu objetivo. Para isso é necessário um ambiente ao qual ele possa interagir (sentindo e realizando ações). Este portifólio trata das estruturas fundamentais de agentes inteligentes, das propriedades dos ambientes em que eles podem atuar e dos tipos de agentes existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739ab28",
   "metadata": {},
   "source": [
    "### Agentes e Ambientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711079b",
   "metadata": {},
   "source": [
    "Um agente inteligente é uma entidade capaz de sentir, perceber o ambiente e tomar alguma ação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed75dd6",
   "metadata": {},
   "source": [
    "![](./agente01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dbff5",
   "metadata": {},
   "source": [
    "Usando a imagem dos materiais de aula como base, a estrutura básica de um agente se dá da seguinte forma:\n",
    "\n",
    "Um **agente**(1) **percebe**(3) o **ambiente**(2) através de **sensores**(4) e realiza alguma **ação**(7) utilizado de **atuadores**(6). A função abstrata que mapeia a ação a partir da percepção do ambiente é chamada de **função agente**(5), enquanto que a implementação dessa função é o **Programa Agente**.\n",
    "\n",
    "A **arquitetura** do agente é o dispositivo com seus sensores e atuadores. O agente em si é a junção da arquitetura com o programa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c3411",
   "metadata": {},
   "source": [
    "### Racionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f8b3e",
   "metadata": {},
   "source": [
    "Para que o agente seja considerado inteligente, ele deve apresentar algum tipo de racionalidade. Mas como se pode expressar a razão em um sistema artificial?\n",
    "\n",
    "As ações do agente, escolhidas a partir das percepções do mesmo são relacionadas a algum tipo de objetivo. Esse objetivo deve ter **medidas de performance** que possibilitem analisar seu sucesso ou insucesso. Maximizar a taxa de sucesso esperada e diminuir ao máximo a chance de insucesso é o que se busca de um agente racional.\n",
    "\n",
    "Quatro pontos são importantes para se decidir o que é racional em determinado momento:\n",
    "\n",
    "```\n",
    "- A medida de desempenho que define o critério de sucesso\n",
    "- O conhecimento prévio do agente sobre o ambiente\n",
    "- As ações que o agente pode realizar\n",
    "- A sequência de percepção do agente até o momento da decisão.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95357a34",
   "metadata": {},
   "source": [
    "### Descrição PEAS (Perfomance, Environment, Actuators, Sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09813608",
   "metadata": {},
   "source": [
    "Para projetar um agente, ter a definição mais completa possível do ambiente é importante. Uma forma de modelar esse ambiente é a partir do **PEAS**, ao qual contém:\n",
    "\n",
    "- A medida de performance desejada\n",
    "- O ambiente da tarefa\n",
    "- Quais os atuadores\n",
    "- Quais os sensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925e62e",
   "metadata": {},
   "source": [
    "#### Pacman Player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46476aed",
   "metadata": {},
   "source": [
    "Para exemplificar a utilização da descrição PEAS, vamos considerar uma IA para jogar o jogo Pacman\n",
    "\n",
    "![](./pacman-stage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73603b",
   "metadata": {},
   "source": [
    "|Tipo de Agente|Medida de Performance|Ambiente|Atuadores|Sensores|\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|Pacman Player|Maximizar o score do jogo<br/>Minimizar o número de mortes|Mapa Virtual 2D|Controles de movimento<br/>(cima, baixo, esquerda e direita)|Posição do player<br/>Posição dos inimigos<br/>Posição dos itens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa52af",
   "metadata": {},
   "source": [
    "Além das características acima, também existem as propriedades do ambiente de tarefas, sendo elas:\n",
    "\n",
    "##### Totalmente Observável / Parcialmente Observável / Não observável\n",
    "\n",
    "Um ambiente totalmente observável é um ambiente cujo agente tem total noção de como todo está todo o ambiente em que ele interage. Um exemplo seria um tabuleiro de xadrez.\n",
    "\n",
    "Um ambiente Parcialmente Observável se trata de um ambiente que não é possível ter toda a informação do mesmo de uma vez. Um exemplo seria o caminho onde atua um carro autonômo.\n",
    "\n",
    "Um ambiente não observável seria um ambiente em que não se tem informações do mesmo.\n",
    "\n",
    "##### Agente único / Multiagente\n",
    "\n",
    "Um ambiente com agente único é um ambiente onde apenas um agente atua naquele ambiente, enquanto que um ambiente multiagente tem mais de um agente atuando. \n",
    "\n",
    "##### Determinístico / Não determinístico\n",
    "\n",
    "Dado um determinado estado de percepção do ambiente, a melhor ação sempre será a mesma se o ambiente for determinístico. Se não, ele é estocástico(não determinístico).\n",
    "\n",
    "##### Episódico / Sequencial\n",
    "\n",
    "Se para chegar a um objetivo, o agente precisa somente de uma ação, então o ambiente é episódico. Caso sejam necessárias mais ações, então é sequencial.\n",
    "\n",
    "##### Estático / Dinâmico\n",
    "\n",
    "Caso o ambiente mude mesmo que o agente não faça nada, ele é dinâmico. Caso o ambiente se mantenha o mesmo até a próxima ação do agente, então ele é estático.\n",
    "\n",
    "##### Discreto / Contínuo\n",
    "\n",
    "Se as ações do agente no ambiente forem ações que ocorrem em determinado período, então o ambiente é discreto. Caso possa tomar a ação a qualquer momento, então o ambiente é contínuo.\n",
    "\n",
    "##### Conhecido / Desconhecido\n",
    "\n",
    "Essa propriedade é definida a partir do conhecimento prévio de agente. Se o agente passa a aprender a agir sem conhecer nada do ambiente, então o ambiente é desconhecido. Caso contrário, é conhecido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1423e",
   "metadata": {},
   "source": [
    "As propriedades do ambiente do _Pacman Player_ neste caso seriam:\n",
    "\n",
    "- **Totalmente Observável**: O agente tem acesso a todo o estado do estágio o tempo todo\n",
    "- **Agente único**: O player é o único agente (desconsiderando os fantasmas programados no jogo)\n",
    "- **Determinístico**: Os fantasmas apresentam padrões de comportamento\n",
    "- **Sequencial**: Conseguir o maior score possível até o _game over_ envolve várias ações\n",
    "- **Dinâmico**: Os fantasmas continuam se movendo independente do player\n",
    "- **Continuo**: O agente deve escolher qual o melhor movimento a qualquer momento (entretanto, o ambiente passa a ser discreto caso o agente consiga perceber o jogo frame a frame)\n",
    "- **Conhecido**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed867f9c",
   "metadata": {},
   "source": [
    "### Programa Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f74159",
   "metadata": {},
   "source": [
    "Um programa agente pode ser de 5 tipos:\n",
    "\n",
    "- Agentes de Reflexo simples\n",
    "- Agentes de Reflexo baseado em modelo\n",
    "- Agentes baseados em objetivos\n",
    "- Agentes utilitários\n",
    "- Agentes com capacidade de aprendizado\n",
    "\n",
    "As imagens usadas nos tópicos a seguir foram retiradas do site [geeksforgeeks](https://www.geeksforgeeks.org/agents-artificial-intelligence/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f1417",
   "metadata": {},
   "source": [
    "#### Agente de Reflexo Simples\n",
    "\n",
    "São agentes que utilizam apenas a percepção atual para decidir suas ações e são implementados com condições simples. Um agente para manter a temperatura de um local dentro de uma faixa pode ser um exemplo. Ele sentiria a temperatura interna do local e talvez a temperatura externa, e ajustar um ar-condicionado ou aquecedor de acordo.\n",
    "\n",
    "![](./simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fb111",
   "metadata": {},
   "source": [
    "#### Agente de Reflexo baseado em modelo\n",
    "\n",
    "Esse tipo de agente, além da percepção atual, passa a ter um estado interno, que considera o histórico de percepções, além de modelos que descrevem como o ambiente muda de acordo com a ação do agente (modelo de transição) e modelos que descrevem o funcionamento e limitações dos sensores (modelo sensorial).\n",
    "\n",
    "![](./model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1683659",
   "metadata": {},
   "source": [
    "#### Agente baseado em objetivos\n",
    "\n",
    "Esse tipo de agente é utilizado para casos onde são necessárias várias ações. Ele utiliza da percepção atual, o histórico de percepções e quais ações podem ser tomadas para chegar mais perto do objetivo. Por se tratar de um ambiente sequencial (os anteriores são para ambiente episódicos), agentes baseados em objetivos já não usam mapeamentos condicionais baseados em simples if/else.\n",
    "\n",
    "![](./objective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa56da",
   "metadata": {},
   "source": [
    "#### Agente Utilitário\n",
    "\n",
    "Um agente utilitário considera mais fatores dentre as escolhas possíveis para alcançar um objetivo. Diferente do agente baseado em objetivos, onde tudo que se busca é chegar mais próximo do objetivo, agentes utilitários utilizam métricas de \"satisfação\", onde se busca a maior satisfação possível para determinada tarefa, mesmo que isso diminua a velocidade a qual se alcança o objetivo.\n",
    "\n",
    "![](./utility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c9b97",
   "metadata": {},
   "source": [
    "#### Agentes com capacidade de aprendizado\n",
    "\n",
    "Estes são agentes que podem aprender conforme interagem com o ambiente. São compostos de 4 componentes(ou elementos) principais:\n",
    "\n",
    "- **Elemento de aprendizado**: melhora o modelo conforme o agente aprende sobre o ambiente\n",
    "- **Elemento critíco**: O elemento de aprendizado coleta feedback deste elemento que descreve o quão bem o agente está indo de acordo com um padrão de performance fixo\n",
    "- **Elemento de performance**: Seleciona a ação externa\n",
    "- **Gerador de problemas**: Sugere novas ações para aumentar as experiências com o ambiente\n",
    "\n",
    "![](./learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606624d",
   "metadata": {},
   "source": [
    "### Representação de Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d20a39",
   "metadata": {},
   "source": [
    "##### Atômica\n",
    "\n",
    "Não existe uma estrutura interna e cada estado do ambiente é uma caixa preta. Exemplos neste caso seriam encontrar uma rota onde cada estado é uma cidade. Essa representação é utilizada para algoritmos de busca, jogos, processos de  decisão de Markov, entre outras.\n",
    "\n",
    "##### Fatorial\n",
    "\n",
    "Cada estado tem propriedades do tipo atributo-valor. Exemplos são localização do GPS, quantidade de combustível em um tanque. Algoritmos para este tipo de representação são algoritmos de satisfação de restrição, redes bayesianas, aprendizado de máquina, entre outros.\n",
    "\n",
    "##### Estruturada\n",
    "\n",
    "Apresenta relacionamentos entre objetos de um estado. Exemplos de algoritmos são lógica de primeira ordem, aprendizado baseado em conhecimento e aprendizado de linguagem natural, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
